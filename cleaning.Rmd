---
title: "Dirty Data Cleaning and Transformation "
author: "Kar Ng"
date: "2021"
output: 
  github_document: 
    toc: true
    toc_depth: 3
always_allow_html: yes

---

***

***

## 1 R PACKAGES

Following codes load required R packages for this project.

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(skimr)
library(agridat)

```


## 2 INTRODUCTION

Data cleaning, manipulation and transformation are very important in data science. They process datasets and convert them into a format of analysis-ready for later analysis such as visualisation or creating predictive models. 

This is a side project to demonstrate data cleaning skills. I will clean a public dataset from "agridate" R package, named "bridges.cucumber". This dataset has actually been cleaned but I downloaded the cleaned format, devastate, ruin and mess it. The single cleaned table has been spitted into 4 tables and with a variability of cleaning tasks. 

![](https://raw.githubusercontent.com/KAR-NG/cleaning/main/pic_4Tables.JPG)



How the original format is like? 

```{r}
data("bridges.cucumber", package = "agridat")
bridges.cucumber

```

It is a dataset that record the experimental result of a cucumber with variables of loc (location), gen (genotype), row (row position of the trial block), col (column position of the trial block) and lastly, the yield.  

This purpose of this project is to show the R codes used to convert the 4 messy tables into this final analysis-ready format. 


## 3 DATA IMPORT

Following codes import the 4 tables. 

```{r}
table1 <- read.csv("cucum1.csv", fileEncoding = "UTF-8-BOM")

table2 <- read.csv("cucum2.csv", fileEncoding = "UTF-8-BOM")

table3 <- read.csv("cucum3.csv", fileEncoding = "UTF-8-BOM")

table4 <- read.csv("cucum4.csv", fileEncoding = "UTF-8-BOM")

```

## 4 DATA CLEANING

### 4.1 Cleaning table 1

Tasks identified:

* Rename the column names.  
* Split the first column into two.  
* Strings manipulation in the first column.  
* Fill up the missing values of the first column.   
* Convert the *4000* in the "row" into 4, according to adjacent values of this column.   
* Convert the *1000* in the "column" into 1,  according to adjacent values of this column.  


**Structural conversion**

In the column of "loc", I have to convert all strings into "Clemson". For the column of "gen", I need to convert those string according to the most likely adjacent value.  

```{r}

table1 <- table1 %>%
  separate("Llocation.genotype", into = c("loc", "gen"), sep = "-") %>% 
  rename(row = rowrow,
         col = column,
         yield = yield.g) %>% 
  mutate(loc = as.factor(loc),
         gen = as.factor(gen))
  

summary(table1)

```

**Cleaning the strings**

```{r}
table1 <- table1 %>% 
  mutate(loc = replace(loc, loc == "", "Clemson"),   # I am already sure that this blank cell is "Clemson".
         loc = replace(loc, loc == "Clem", "Clemson"),
         loc = replace(loc, loc == "Clem_son", "Clemson"),
         loc = replace(loc, loc == "CLEMSON", "Clemson"),
         loc = as.character(loc),                    # for factor's levels cleaning. 
         gen = as.character(gen),                    # To use case when, variable has to be character
         gen = case_when(gen == "" ~ "Dasher",       # Same nature as replace, I know this blank is "Dasher".
                         gen == "poinsett" ~ "Poinsett",
                         gen == "s" ~ "Sprint",
                         TRUE ~ gen)) %>% 
  mutate_if(is.character, as.factor)

summary(table1)

```

**Cleaning outlier values in row and col**

```{r}

table1 <- table1 %>% 
  mutate(row = replace(row, row == 4000, 4),
         col = replace(col, col == 1000, 1))
  
summary(table1)

```

### 4.2 Cleaning table  2

```{r}
summary(table2)

```

