---
title: "Dirty Data Cleaning and Transformation "
author: "Kar Ng"
date: "2021"
output: 
  github_document: 
    toc: true
    toc_depth: 3
always_allow_html: yes

---

***

![](https://raw.githubusercontent.com/KAR-NG/Dirty-Data-Challenge-/main/pic4_thumbnail.png)

***

## 1 R PACKAGES

Following codes load required R packages for this project.

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(skimr)
library(agridat)
library(caret)

```


## 2 INTRODUCTION

Data cleaning, manipulation and transformation are very important in data science. They process datasets and convert them into a format that is usable for later analysis such as visualisation and creating predictive models. 

This project is a side project to demonstrate my data cleaning skills. This project works on a simple dataset with many common cleaning tasks. I hope this project is comprehensive enough for your reference. You could visit my other projects on my [Github](https://github.com/KAR-NG) repository to view how I cleaned up other projects.

In this project, I will clean a public dataset from a R package - "agridate", the dataset is called "bridges.cucumber". This dataset has actually been cleaned but I downloaded the data, devastate, ruin and mess it. The single cleaned table has been spitted into 4 tables with a numbers of cleaning tasks. 

![](https://raw.githubusercontent.com/KAR-NG/Dirty-Data-Challenge-/main/pic0_4tables.png)


Following is the original dataset, which will be used for comparison in section 5.  

```{r}
data("bridges.cucumber", package = "agridat")
bridges.cucumber

```

This dataset records the results of a cucumber experiment with variables - loc (location), gen (genotype), row (row position of the trial block), col (column position of the trial block) and lastly, the yield.  


## 3 DATA IMPORT

Following codes import the 4 tables. 

```{r}
table1 <- read.csv("cucum1.csv", fileEncoding = "UTF-8-BOM")

table2 <- read.csv("cucum2.csv", fileEncoding = "UTF-8-BOM")

table3 <- read.csv("cucum3.csv", fileEncoding = "UTF-8-BOM")

table4 <- read.csv("cucum4.csv", fileEncoding = "UTF-8-BOM")

```

## 4 DATA CLEANING

In the upcoming cleanings of this project, you may see a more complicated way to clean the data because this kind of procedures have higher transferability between datasets or projects instead of just relying on simple cleaning techniques that only works in this project. My cleanings will be a mix of both. 


### 4.1 Cleaning table 1

Main tasks identified from table 1:

![](https://raw.githubusercontent.com/KAR-NG/Dirty-Data-Challenge-/main/pic1_table1.JPG)


* Rename the column names.  
* Split the first column into two.  
* Strings manipulation and extraction in the first column.  
* Fill up the missing values of the first column.   
* Convert the *4000* in the "row" into 4, according to adjacent values of this column.   
* Convert the *1000* in the "column" into 1,  according to adjacent values of this column.  
* The last two rows of "Llocation-genotype" have too many missing values and these rows will be removed. 
* Imputation of two of the NA in the column "yield" by imputation model.

**Step 1ï¼š Cleaning column 1 by Rename + lower case + remove punctuation**

```{r}
t1 <- table1 %>% 
  rename("loc_gen" = Llocation.genotype,
         row = rowrow,
         col = column,
         yield = yield.g) %>% 
  mutate(loc_gen = str_to_lower(loc_gen),
         loc_gen = str_replace_all(loc_gen, "[[:punct:]]", " "),
         loc_gen = replace(loc_gen, loc_gen == " ", NA)) 

t1

```

**Step 2: Fill up the missing value in loc_gen.** 

I observed that the empty cell should be "clemson dasher" as compared to adjacent strings and the frequency of this combination in the entire dataset.

```{r}

t1_temp <- t1 %>% 
  mutate(comment = ifelse(is.na(loc_gen), "Was a NA -->", ""),
         loc_gen = replace(loc_gen, is.na(loc_gen), "clemson dasher")) %>% 
  relocate(comment, .before = loc_gen)

t1_temp 

```

**Step 3: Create loc and gen from log_gen**

```{r}
# set up df

t1 <- t1_temp %>% dplyr::select(-comment)

# set up rules

loc <- "clemson|clem|c"          # Observe from table 1 I know that loc is clemson
gen <- c("dasher|guardian|poinsett|sprint") # Observe from table 1 I know these are gen 

# get loc and gen, and remove loc_gen 

t1 <- t1 %>% 
  mutate(loc = str_extract(loc_gen, loc),
         gen = str_extract(loc_gen, gen),
         gen = ifelse(loc_gen == "i am pretty sure this is clemson s", "sprint", gen)) %>% 
  mutate(gen = ifelse(str_detect(loc_gen,"in this cell"), "sprint", gen)) %>% 
  dplyr::select(-loc_gen) %>% 
  relocate(loc, .before = row) %>% 
  relocate(gen, .after = loc) %>% 
  mutate(loc = ifelse(loc == "clem", "clemson", loc)) %>% 
  mutate_if(is.character, as.factor)
  
t1 

```

In table 1, the "loc" has only 1 level called "clemson".

```{r}
levels(t1$loc)

```
In table 1, the "gen" has 4 levels. 

```{r}
levels(t1$gen)

```

**Step 4: Get perfect loc and gen column.**

Calculating the number of missing values in each row of data, not column.   

* Row 17 and 18 have the highest number of missing values. 
* They will be removed. 

```{r}
 t1 %>% 
  mutate(id = row_number()) %>% 
  gather(key = "variable", value = "value", -6) %>% 
  mutate(max.number.of.variables = n_distinct(variable)) %>% 
  filter(is.na(value)) %>% 
  group_by(id, max.number.of.variables) %>% 
  summarise(count = n()) %>% 
  mutate(InfoLost.percent = paste0(count/max.number.of.variables * 100, "%"))
  

```
Checking row 17 and 18, these rows are having their important information missing. 

```{r}
t1[c(17:18), ]
  
```

Additionally, all levels of "gen" have 4 replicates and only "sprint" has 6 replicates. It is obvious that row 17 and 18 are errors and should be removed.

```{r}
t1 %>% group_by(gen) %>% summarise(count = n())

```
Removing row 17 and 18.

```{r}
t1 <- t1[-c(17, 18),]
t1 %>% group_by(gen) %>% summarise(count = n())
```

Now, the removal of row 17 and 18 has been successful. Comming up, I will clean up the 4000 and 1000 in the "row" and "col" columns.
 
**Step 5: Cleaning outlier values in row and col**

```{r}

table1 <- t1 %>% 
  mutate(row = replace(row, row == 4000, 4),
         col = replace(col, col == 1000, 1))
  
summary(table1)

```

The cleaning of table 1 has now considered completed. There are two missing values in the *yield*, I will fill them up with imputation model after combining other tables into this table in section 4.5. 


### 4.2 Cleaning table 2

Main tasks identified:

![](https://raw.githubusercontent.com/KAR-NG/Dirty-Data-Challenge-/main/pic2_table2.JPG)

* Trim leading and trailing white spaces.  
* Remove the first column.  
* Rename column names.  
* Clean the strings in location and genotype.
* Combine yield_x, yield_y, and yield_z


**Structural and variable names conversion**

```{r}
tbl2 <- table2 %>% 
  rename(loc = Llocation,             # Change variable names
         gen = genotype,
         row = rowrow,
         col = colu....mn) %>% 
  select(-X) %>%                      # remove first column
  mutate(loc = trimws(loc),           # trim leading and trailing white spaces 
         gen = trimws(gen)) %>% 
  mutate_if(is.character, as.factor)  # changing character variables to factor


summary(tbl2)

```

In the column "loc", all values are actually "Tifton" based on the original dataset, and it is my job to convert all other strings into "Tifton". In the column "gen", I will need to rectify a typo of Poinsett and fill up 2 blank cells. 

**Cleaning the strings**

```{r}
tbl2 <- tbl2 %>% 
  mutate_if(is.factor, as.character) %>% 
  mutate(loc = case_when(loc == "t" ~ "Tifton",
                         loc == "T" ~ "Tifton",
                         loc == "Ti   fton" ~ "Tifton",
                         loc == "Tif" ~ "Tifton",
                         TRUE ~ loc),
         loc = replace(loc, loc == "Tiftaaon", "Tifton"),
         gen = replace(gen, gen == "Poi    nsett", "Poinsett"),
         gen = replace(gen, gen == "", NA)) %>% 
  fill(gen) %>%                               
  mutate_if(is.character, as.factor)


summary(tbl2)


```

Next I will need to combine yield x, y, and z into 1 single column with a name, "yield".

**Combine the column yield x, y and z**

```{r}
table2 <- tbl2 %>%
  mutate(yield = paste0(yield.x, yield_y, yield_z)) %>% 
  mutate(yield = str_remove_all(yield, pattern = "NA")) %>% 
  select(-5, -6, -7)

table2
 


```

The cleaning of table 2 has now completed.


### 4.3 Cleaning tables 3 and 4

This section will clean 3 and 4 together and combine them into 1.

Main tasks identified:

![](https://raw.githubusercontent.com/KAR-NG/Dirty-Data-Challenge-/main/pic3_table3_table4.JPG)

* Merge 2 tables together.  
* Rename variable names.  
* Remove the irrelevant row 3 (id = 3).     
* Fix the typo "10" in the column of ROW in table 4.
* Convert the levels of location and genotype into a proper case with only the first character being upper case.    


```{r}
table3 <- table3 %>% 
  left_join(table4, by = "id") %>% 
  select(-1) %>% 
  rename(loc = LOCATION,
         gen = GENOTYPE,
         row = ROW,
         col = COLUMN,
         yield = YIELD.G) %>% 
  mutate(loc = replace(loc, loc == "TIFTON", "Tifton"),
         gen = replace(gen, gen == "SPRINT", "Sprint")) %>% 
  filter(loc != "GATTON")


```

The cleaning of tables 3 and 4 has now completed.

### 4.4  Combine all tables

Finally, 3 tables are combined into one final table. 

```{r}
final_table <- rbind(table1, table2, table3)

final_table <- final_table %>% 
  mutate(yield = as.double(yield))

# a bit of cleaning

final_table <- final_table %>% 
  mutate(loc = str_to_lower(loc),
         gen = str_to_lower(gen)) %>% 
  mutate_if(is.character, as.factor) %>% 
  arrange(loc, gen, row, col)

final_table

```


### 4.5 Missing value Imputation

Last but not least, there are 2 missing values in the "yield" column and I will fill them up using imputation model to predict the most possible values based on adjacent similar data. 

```{r}
colSums(is.na(final_table))
```


Imputation technique I am applying is a type of machine learning imputation model that will use all columns in the dataset to predict these missing values. I am using the imputation function from R's "caret" package. 

To use the function, I will need to convert all factor variables into dummy data.

```{r}
# Dummy transformation

dummy.variables <- dummyVars(~., data = final_table)
final_table_dum <- dummy.variables %>% predict(final_table)  

head(final_table_dum)

```

Assessing the number of missing values again. 

```{r}
colSums(is.na(final_table_dum))

```

Imputation using the bagging technique of decision trees. 

```{r}
set.seed(123)

imputation.model <- preProcess(final_table_dum, method = "bagImpute")
imputed.final.table <- imputation.model %>% predict(final_table_dum)
imputed.final.table

```
Overwrite the "yield" of the final_table. 

```{r}
final_table$yield <- imputed.final.table[, 9]

```

Checking the present in the dataset and the result shows that the imputation has been successful.  

```{r}
colSums(is.na(final_table))

```


## 5. Data "health check"

All data are with correct type that are readied for machine learning prediction. 

```{r}
glimpse(final_table)

```

Now, I can clearly see that there are two location "Clemson" and "Tifton" as well as 4 cucumber genotypes in the column of "gen". Both variables have equal sample sizes (16 and 8) among their attribute (or known as "level"). 

```{r}
summary(final_table)
```

This project is not meant to draw graphs but I am drawing one to inspect and compare my final cleaned table with the original dataset from the R package, named "bridges.cucumber". 

```{r, fig.width=8}

# Set up dataframe / combine final table with the original dataset

group <- rep(c("final_table", "original"), each = 32)
test <- rbind(final_table, bridges.cucumber)
test <- cbind(group, test)

# Plot

ggplot(test, aes(x = fct_reorder(gen, yield), y = yield, fill = group)) +
  geom_boxplot() +
  facet_wrap(~ group, scales = "free_x") +
  theme_bw() +
  theme(legend.position = "none",
        strip.text = element_text(size = 12),
        axis.title.x = element_text(margin = margin(10, 0, 0, 0)),
        axis.title.y = element_text(margin = margin(0, 10, 0, 0)),
        plot.title = element_text(face = "bold", vjust = 2)) +
  labs(x = "Cucumber genotype",
       y = "Yield, g",
       title = "Comparing Final Table with the Original to Check for Disparity")

  
```

There were two missing values in guardian and dasher of final_table filled up by estimates from the imputation model. That is why the guardian and dasher of two dataset seems a little bit different. However, the difference is minor and not dramatic. 

Finally, following is my cleaned dataset combined from the 4 messy tables and is ready for storage or any analysis.

```{r}
final_table

```



## 5 CONCLUSION

In conclusion, this project successfully uses R codes to clean and combine four messy tables into one that has a perfect format for storage or statistical analysis.



*Thank you for reading!*


## 6 REFERENCE

https://cran.r-project.org/web/packages/agridat/agridat.pdf


